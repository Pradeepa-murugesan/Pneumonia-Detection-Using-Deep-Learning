{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LuqhRGNWfLh"
      },
      "source": [
        "# PDFPlumber\n",
        "\n",
        "Like PyMuPDF, the output Documents contain detailed metadata about the PDF and its pages, and returns one document per page.\n",
        "\n",
        "## Overview\n",
        "### Integration details\n",
        "\n",
        "| Class | Package | Local | Serializable | JS support|\n",
        "| :--- | :--- | :---: | :---: |  :---: |\n",
        "| [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | ✅ | ❌ | ❌ |\n",
        "### Loader features\n",
        "| Source | Document Lazy Loading | Native Async Support\n",
        "| :---: | :---: | :---: |\n",
        "| PDFPlumberLoader | ✅ | ❌ |\n",
        "\n",
        "## Setup\n",
        "\n",
        "### Credentials\n",
        "\n",
        "No credentials are needed to use this loader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKg8X9SkWfLk"
      },
      "source": [
        "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktSW28ynWfLl"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjrutg0dWfLm"
      },
      "source": [
        "### Installation\n",
        "\n",
        "Install **langchain_community**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oy6dv8exWfLm"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL16vSokWfLn"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "Now we can instantiate our model object and load documents:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU pdfplumber"
      ],
      "metadata": {
        "id": "FPbH_XyEXEot",
        "outputId": "a81c791c-f1a6-4ada-d9c4-a1c7336ed3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bR2fRDioWfLn"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "import pdfplumber\n",
        "loader = PDFPlumberLoader(\"/content/drive/MyDrive/NLP_System/Mlops_book.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lk2fZOYWfLn"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VU3jtq-BWfLn",
        "outputId": "7c7e53e1-6749-404b-8bb5-4d850fca67ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/MyDrive/NLP_System/Mlops_book.pdf', 'file_path': '/content/drive/MyDrive/NLP_System/Mlops_book.pdf', 'page': 0, 'total_pages': 616, 'Title': 'Practical MLOps', 'Author': 'Noah Gift & Alfredo Deza', 'Creator': '', 'Producer': 'ConvertAPI', 'CreationDate': \"D:20240924203520+00'00'\", 'ModDate': \"D:20240924203530+00'00'\"}, page_content='\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "docs = loader.load()\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9luM6poaWfLo",
        "outputId": "b17eb63d-1607-436b-8ef2-d40e0d285d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': '/content/drive/MyDrive/NLP_System/Mlops_book.pdf', 'file_path': '/content/drive/MyDrive/NLP_System/Mlops_book.pdf', 'page': 0, 'total_pages': 616, 'Title': 'Practical MLOps', 'Author': 'Noah Gift & Alfredo Deza', 'Creator': '', 'Producer': 'ConvertAPI', 'CreationDate': \"D:20240924203520+00'00'\", 'ModDate': \"D:20240924203530+00'00'\"}\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srPCpgDmWfLo"
      },
      "source": [
        "## Lazy Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "H5RkCXOYWfLo"
      },
      "outputs": [],
      "source": [
        "page = []\n",
        "for doc in loader.lazy_load():\n",
        "    page.append(doc)\n",
        "    if len(page) >= 10:\n",
        "        # do some paged operation, e.g.\n",
        "        # index.upsert(page)\n",
        "\n",
        "        page = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(page[0]))  # Replace page[0] with any valid Document object\n"
      ],
      "metadata": {
        "id": "1bJJXr9ZaCcA",
        "outputId": "8adbfa9c-f636-4e3e-a62a-33445987dc6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_check_frozen', '_copy_and_set_values', '_get_value', '_iter', 'cast_id_to_str', 'construct', 'copy', 'dict', 'from_orm', 'get_lc_namespace', 'id', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'metadata', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'page_content', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'to_json', 'to_json_not_implemented', 'type', 'update_forward_refs', 'validate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Convert Document objects to a serializable format\n",
        "serializable_pages = [{\"content\": doc.page_content} for doc in page]\n",
        "\n",
        "# Save the content to a JSON file\n",
        "with open(\"/content/drive/MyDrive/processed_pages.json\", \"w\") as file:\n",
        "    json.dump(serializable_pages, file, indent=4)\n",
        "\n",
        "print(\"Document content has been saved to processed_pages.json.\")\n"
      ],
      "metadata": {
        "id": "-6Z3w3m2Zkt0",
        "outputId": "ee1bbda2-5774-415d-9d37-0589a3d233d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document content has been saved to processed_pages.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you are using some document loader or extractor\n",
        "page = []\n",
        "for doc in loader.lazy_load():  # Replace this with your own loader\n",
        "    page.append(doc)\n",
        "    if len(page) >= 10:  # Or however many pages you want to process at once\n",
        "        break  # Just for testing purposes, processes the first 10 pages\n",
        "\n",
        "# Now, check the contents of the page list\n",
        "print(len(page))  # Verify there are elements\n",
        "if len(page) > 0:\n",
        "    print(type(page[0]))  # Check the type of the first element\n",
        "    print(page[0])  # View the content of the first element\n"
      ],
      "metadata": {
        "id": "7Xcn1cBXdrSQ",
        "outputId": "e2bf5bfe-6377-4c41-8f44-59c3f477851e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "<class 'langchain_core.documents.base.Document'>\n",
            "page_content='\n",
            "' metadata={'source': '/content/drive/MyDrive/NLP_System/Mlops_book.pdf', 'file_path': '/content/drive/MyDrive/NLP_System/Mlops_book.pdf', 'page': 0, 'total_pages': 616, 'Title': 'Practical MLOps', 'Author': 'Noah Gift & Alfredo Deza', 'Creator': '', 'Producer': 'ConvertAPI', 'CreationDate': \"D:20240924203520+00'00'\", 'ModDate': \"D:20240924203530+00'00'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Convert Document objects to a serializable format\n",
        "serializable_pages = [{\"content\": doc.page_content} for doc in page]\n",
        "\n",
        "# Save the content to a JSON file\n",
        "with open(\"processed_pages.json\", \"w\") as file:\n",
        "    json.dump(serializable_pages, file, indent=4)\n",
        "\n",
        "print(\"Document content has been saved to processed_pages.json.\")\n"
      ],
      "metadata": {
        "id": "nIpu4kBxdcXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjyS0IbWc_CM",
        "outputId": "c6392372-fe33-4f53-978e-c90152c5ea2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-20-8ec17d83d1e4>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-8ec17d83d1e4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    how to read json file\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON data from the saved file\n",
        "with open(\"processed_pages.json\", \"r\") as file:\n",
        "    loaded_pages = json.load(file)\n",
        "\n",
        "# Print the loaded data to verify it\n",
        "for idx, page in enumerate(loaded_pages):\n",
        "    print(f\"Page {idx + 1} content: {page['content'][:500]}...\")  # Print first 500 characters for quick inspection\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xIH-RhXRa-Sp",
        "outputId": "f6894256-a2e2-4a08-a70a-952a5cd8a40f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page 1 content: Mechanical Turk data labeling, Mechanical Turk Data Labeling\n",
            "SQS queue, defined, Key Terms\n",
            "SSH access, Running a Container\n",
            "statistics, descriptive, Descriptive Statistics and Normal Distributions-\n",
            "Descriptive Statistics and Normal Distributions\n",
            "supervised machine learning, Machine Learning Key Concepts\n",
            "swagger, defined, Key Terms\n",
            "T\n",
            "Taleb, Nassim, Focus on Prediction Accuracy Versus the Big Picture\n",
            "target dataset, baseline dataset versus, Monitoring Drift with AWS\n",
            "SageMaker\n",
            "task tracking (in tech...\n",
            "Page 2 content: technical project management, Technical Project Management-Task Tracking\n",
            "as DevOps best practice, DevOps and MLOps\n",
            "project plan, Project Plan\n",
            "task tracking, Task Tracking\n",
            "weekly demo, Weekly Demo\n",
            "technology certifications (see certifications)\n",
            "TensorFlow\n",
            "converting into ONNX, Convert TensorFlow into ONNX-Convert\n",
            "TensorFlow into ONNX\n",
            "TFHub, TFHub\n",
            "TensorFlow Developer Certificate, GCP\n",
            "TensorFlow Playground, Optimization\n",
            "TensorFlow Processing Unit (see TPU)\n",
            "\"10X better\" education system, 10X Better ...\n",
            "Page 3 content: TFHub (TensorFlow Hub), TFHub\n",
            "theory of competitive advantage, Using the “No Code/Low Code” AWS\n",
            "Comprehend solution\n",
            "Thiel, Peter, Current State of Higher Education That Will Be Disrupted\n",
            "token-based authentication, Authenticating API Services\n",
            "TPU (TensorFlow Processing Unit)\n",
            "Coral Project and, Coral-Coral\n",
            "porting over non-TPU models, Porting Over Non-TPU Models-Porting\n",
            "Over Non-TPU Models\n",
            "troubleshooting\n",
            "Application Insights, Application Insights\n",
            "debugging locally, Debugging Locally-Debugging Lo...\n",
            "Page 4 content: virtual environment, Python, Implementing DevOps\n",
            "virtual machines\n",
            "containers versus, Containers\n",
            "defined, Key Terms\n",
            "vision (see computer vision)\n",
            "Y\n",
            "YAML, defined, Key Terms\n",
            "Z\n",
            "Zhang, Feng, AutoML\n",
            "ZSH, Bash Shell and Commands, Configuration\n",
            "...\n",
            "Page 5 content: About the Authors\n",
            "Noah Gift is the founder of Pragmatic A.I. Labs. He lectures at MSDS, at\n",
            "Northwestern, Duke MIDS Graduate Data Science Program, the Graduate\n",
            "Data Science program at UC Berkeley, the UC Davis Graduate School of\n",
            "Management MSBA program, UNC Charlotte Data Science Initiative, and\n",
            "University of Tennessee (as part of the Tennessee Digital Jobs Factory). He\n",
            "teaches and designs graduate machine learning, MLOps, AI, and data science\n",
            "courses, and consults on machine learning and cloud a...\n",
            "Page 6 content: Colophon\n",
            "The animal on the cover of Practical MLOps is a Dalmatian (Canis lupus\n",
            "familiaris). Though now found around the globe, this breed of dog can be\n",
            "traced back to present-day Croatia in the historical Dalmatia region.\n",
            "The Dalmatian is a medium-sized muscular dog that stands between 19 to 23\n",
            "inches (or 48 to 58 cm) and has a distinctive white coat with black spots. A\n",
            "highly cultivated breed, these dogs are popular family pets as well as\n",
            "entrants in kennel club competitions. They display prop...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON data\n",
        "with open(\"processed_pages.json\", \"r\") as file:\n",
        "    loaded_pages = json.load(file)\n",
        "\n",
        "# Access content for NLP processing\n",
        "for page in loaded_pages:\n",
        "    print(page[\"content\"])  # Process each page's content\n"
      ],
      "metadata": {
        "id": "f7iZeGPSbNAu",
        "outputId": "bc5dfb45-6043-462d-908c-38c7f2f253e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mechanical Turk data labeling, Mechanical Turk Data Labeling\n",
            "SQS queue, defined, Key Terms\n",
            "SSH access, Running a Container\n",
            "statistics, descriptive, Descriptive Statistics and Normal Distributions-\n",
            "Descriptive Statistics and Normal Distributions\n",
            "supervised machine learning, Machine Learning Key Concepts\n",
            "swagger, defined, Key Terms\n",
            "T\n",
            "Taleb, Nassim, Focus on Prediction Accuracy Versus the Big Picture\n",
            "target dataset, baseline dataset versus, Monitoring Drift with AWS\n",
            "SageMaker\n",
            "task tracking (in technical project management), Task Tracking\n",
            "technical communication (DevOps best practice), DevOps and MLOps\n",
            "technical portfolio, building a, Building a Technical Portfolio for MLOps-\n",
            "Getting a Job: Don’t Storm the Castle, Walk in the Backdoor\n",
            "project example: cloud native ML application or API, Project: Build\n",
            "Cloud Native ML Application or API\n",
            "project example: Docker and Kubernetes container project, Project:\n",
            "Docker and Kubernetes Container Project\n",
            "project example: edge ML solution, Project: Build Edge ML Solution\n",
            "project example: serverless AI data engineering pipeline, Project:\n",
            "Serverless AI Data Engineering Pipeline\n",
            "strategies for getting a job, Getting a Job: Don’t Storm the Castle, Walk\n",
            "in the Backdoor\n",
            "\n",
            "technical project management, Technical Project Management-Task Tracking\n",
            "as DevOps best practice, DevOps and MLOps\n",
            "project plan, Project Plan\n",
            "task tracking, Task Tracking\n",
            "weekly demo, Weekly Demo\n",
            "technology certifications (see certifications)\n",
            "TensorFlow\n",
            "converting into ONNX, Convert TensorFlow into ONNX-Convert\n",
            "TensorFlow into ONNX\n",
            "TFHub, TFHub\n",
            "TensorFlow Developer Certificate, GCP\n",
            "TensorFlow Playground, Optimization\n",
            "TensorFlow Processing Unit (see TPU)\n",
            "\"10X better\" education system, 10X Better Education-Disruption of hiring\n",
            "process\n",
            "Terrell, Dave, Focus on Prediction Accuracy Versus the Big Picture\n",
            "testing\n",
            "automated checks, Automated checks\n",
            "continuous improvement and, Continuous improvement\n",
            "linting, Linting\n",
            "model deployment, Testing Techniques for Model Deployment-\n",
            "Continuous improvement\n",
            "Python code, Getting Started with Cloud Computing\n",
            "\n",
            "TFHub (TensorFlow Hub), TFHub\n",
            "theory of competitive advantage, Using the “No Code/Low Code” AWS\n",
            "Comprehend solution\n",
            "Thiel, Peter, Current State of Higher Education That Will Be Disrupted\n",
            "token-based authentication, Authenticating API Services\n",
            "TPU (TensorFlow Processing Unit)\n",
            "Coral Project and, Coral-Coral\n",
            "porting over non-TPU models, Porting Over Non-TPU Models-Porting\n",
            "Over Non-TPU Models\n",
            "troubleshooting\n",
            "Application Insights, Application Insights\n",
            "debugging locally, Debugging Locally-Debugging Locally\n",
            "deployment issues, Troubleshooting Deployment Issues-Debugging\n",
            "Locally\n",
            "retrieving logs, Retrieving Logs\n",
            "U\n",
            "unsupervised machine learning, Machine Learning Key Concepts-Machine\n",
            "Learning Key Concepts\n",
            "USB Accelerator, Coral\n",
            "utilscli.py, MLOps Cookbook on AWS\n",
            "V\n",
            "versioning, of datasets, Versioning Datasets\n",
            "Vertex AI, Google Cloud Platform Overview\n",
            "\n",
            "virtual environment, Python, Implementing DevOps\n",
            "virtual machines\n",
            "containers versus, Containers\n",
            "defined, Key Terms\n",
            "vision (see computer vision)\n",
            "Y\n",
            "YAML, defined, Key Terms\n",
            "Z\n",
            "Zhang, Feng, AutoML\n",
            "ZSH, Bash Shell and Commands, Configuration\n",
            "\n",
            "About the Authors\n",
            "Noah Gift is the founder of Pragmatic A.I. Labs. He lectures at MSDS, at\n",
            "Northwestern, Duke MIDS Graduate Data Science Program, the Graduate\n",
            "Data Science program at UC Berkeley, the UC Davis Graduate School of\n",
            "Management MSBA program, UNC Charlotte Data Science Initiative, and\n",
            "University of Tennessee (as part of the Tennessee Digital Jobs Factory). He\n",
            "teaches and designs graduate machine learning, MLOps, AI, and data science\n",
            "courses, and consults on machine learning and cloud architecture for students\n",
            "and faculty. As a former CTO, individual contributor, and consultant he has\n",
            "over 20 years’ experience shipping revenue-generating products in many\n",
            "industries including film, games, and SaaS.\n",
            "Alfredo Deza is a passionate software engineer, speaker, author, and former\n",
            "Olympic athlete with almost two decades of DevOps and software\n",
            "engineering experience. He currently teaches machine learning engineering\n",
            "and gives worldwide lectures about software development, personal\n",
            "development, and professional sports. Alfredo has written several books\n",
            "about DevOps and Python, and continues to share his knowledge about\n",
            "resilient infrastructure, testing, and robust development practices in courses,\n",
            "books, and presentations.\n",
            "\n",
            "Colophon\n",
            "The animal on the cover of Practical MLOps is a Dalmatian (Canis lupus\n",
            "familiaris). Though now found around the globe, this breed of dog can be\n",
            "traced back to present-day Croatia in the historical Dalmatia region.\n",
            "The Dalmatian is a medium-sized muscular dog that stands between 19 to 23\n",
            "inches (or 48 to 58 cm) and has a distinctive white coat with black spots. A\n",
            "highly cultivated breed, these dogs are popular family pets as well as\n",
            "entrants in kennel club competitions. They display propensities for health\n",
            "problems related to their breeding (including deafness, allergies, and urinary\n",
            "stones) and typically have a lifespan between 11 and 13 years. The\n",
            "Dalmatian was bred as a hunting dog, but then were often used as carriage\n",
            "dogs, trotting alongside horse-drawn carriages of the wealthy to protect the\n",
            "carriages and their inhabitants, and were considered status symbols during\n",
            "the Regency period in England. They would also commonly protect the\n",
            "horses and carriages of brewers, Romani caravans, and firefighters.\n",
            "Many of the animals on O’Reilly covers are endangered; all of them are\n",
            "important to the world.\n",
            "The cover illustration is by Karen Montgomery, based on a black and white\n",
            "engraving from Wood’s Animate Creation. The cover fonts are Gilroy\n",
            "Semibold and Guardian Sans. The text font is Adobe Minion Pro; the heading\n",
            "font is Adobe Myriad Condensed; and the code font is Dalton Maag’s Ubuntu\n",
            "Mono.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9o20Nn3WfLp"
      },
      "source": [
        "## API reference\n",
        "\n",
        "For detailed documentation of all PDFPlumberLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}